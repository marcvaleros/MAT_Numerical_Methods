---
title: "MAT 5101 - Problem Set 3"
subtitle: "Group 2"
author: "Erik Celdran, Jade Rosales, Marc Valeros"
date: "2024-04-02"
output: pdf_document
header-includes: |
  \usepackage{graphicx}
  \graphicspath{ {figures/} }
  \usepackage{array}
  \usepackage{amsmath}
  \usepackage{xcolor}
  \usepackage{bigints}
  \graphicspath{ {./} }
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(PolynomF)
library(matrixcalc)
library(pracma)
```
## Problem Set 3

1. If $e^{1.3}$ is approximated by Lagrangian interpolation from the values for $e^0=1, e^1=2.7183$, and $e^2=7.3891$, what are the minimum and maximum estimates for the error? Compare to the actual error.

The basic Lagrange polynomials are:
$$
\begin{aligned}
& L_0(x)=\frac{(x-1)(x-2)}{(0-1)(0-2)} \\
& L_1(x)=\frac{x(x-2)}{1(1-2)} \\
& L_2(x)=\frac{x(x-1)}{2(2-1)}
\end{aligned}
$$

Thus,
$$
P(x)=L_0(x)+e^1 \cdot L_1(x)+ e^2 \cdot L_2(x) .
$$

```{r}
 p=function(x){((x-1)*(x-2))/((0-1)*(0-2))+
 exp(1)*x*(x-2)/(1*(1-2))+
 exp(2)*x*(x-1)/(2*(2-1))}

 f=function(x){exp(x)}
 
 actualerror=abs(f(1.3)-p(1.3))
 actualerror

```

The error term is
$$
E_2(x, f)=x(x-0.6)(x-0.9) \frac{f^{\prime \prime \prime}(\xi(x))}{3 !}
$$
Let $g(x)=x(x-1)(x-2)$. Then $g'(x)=3x^2-6x+2 \rightarrow x=1.5773502269, 0.4226497308$

```{r}
g=function(x){x*(x-1)*(x-2)}

g(1.5773502269)
minimum_error = abs(exp(0)/6 * g(1.5773502269))
minimum_error

g(0.4226497308)
maximum_error = abs(exp(2)/6 * g(0.4226497308))
maximum_error
```

Therefore, $0.06415003$ and $0.4740082$ are the minimum and maximum error estimates respectively.
While the actual error is $0.1402057$.

2. Construct the divided-difference table from these data:
\begin{tabular}{cccccc}
$x$ & -0.2 & 0.3 & 0.7 & -0.3 & 0.1 \\
$f(x)$ & 1.23 & 2.34 & -1.05 & 6.51 & -0.06
\end{tabular}

Use the divided-difference table to interpolate for $f(0.4)$.

In general,
$$
f\left[x_s, x_t\right]=\frac{f_t-f_s}{x_t-x_s}=\frac{f_s-f_t}{x_s-x_t} .
$$

Notice that the order of the points is immaterial.
The second- and higher-order differences are defined in terms of lower-order differences. For example,
$$
\begin{gathered}
f\left[x_0, x_1, x_2\right]=\frac{f\left[x_1, x_2\right]-f\left[x_0, x_1\right]}{x_2-x_0} \\
f\left[x_0, x_1, \cdots, x_n\right]=\frac{f\left[x_1, x_2, \cdots, x_n\right]-f\left[x_0, x_1, \cdots, x_{n-1}\right]}{x_n-x_0} .
\end{gathered}
$$


3. You have these values for $x$ and $f(x)$ :
\begin{tabular}{cccccc}
$x$ & -0.2 & 0.3 & 0.7 & -0.3 & 0.1 \\
$f(x)$ & 1.23 & 2.34 & -1.05 & 6.51 & -0.06
\end{tabular}

Find $f(0.5)$ from a cubic that starts from $x=0.1$.



4. Given function $f(x)=2 x \cos (2 x)$. Use a central difference to compute $f^{\prime}(2.0)$ and compare it using the $P^{\prime}(x)$.


5. Use Trapezoid rule to estimate $\int_1^2 \frac{1}{x^2} d x$. Accurate within 0.001 .

To get the interval we must solve for the error bound using this formula:

Error in $T_n \leq \frac{M(b-a)^2}{12 n^2}$. Where M is at maximum value when $f''(1)$

$$0.001 \leq \frac{f''(1)(b-a)^2}{12 n^2}$$
$$0.001 \leq \frac{6}{12 n^2}$$
$$n^2 \leq \frac{6}{12 \cdot 0.001}$$
$$n \leq \sqrt\frac{6}{0.012}$$
$$n \leq 22.361$$

Trapezoid rule formula: 

$T_n=\frac{\Delta x}{2}\left(f\left(x_0\right)+2 f\left(x_1\right)+2 f\left(x_2\right)+\cdots+2 f\left(x_{n-1}\right)+f\left(x_n\right)\right.$.

Using 23 intervals

```{r}
f=function(x){1/x^2}

# Define the limits of integration
a=1
b=2

# Number of intervals
n=23

# Width of each interval
h=(b - a) / n

# Trapezoid rule formula
int=(h / 2) * (f(a) + 2 * sum(sapply(1:(n-1), function(i) f(a + i * h))) + f(b))

actual=integrate(f, lower = 1, upper = 2)
abs(actual$value-int)
```


6. Use Simpson's rule to estimate $\int_1^2 \frac{1}{x^2} d x$. Accurate within 0.001 .

Error in $S_n \leq \frac{M(b-a)^5}{180 n^4}$. Where M is at maximum value when $f^4(1)$

$$0.001 \leq \frac{f^4(1)(b-a)^2}{180 n^4}$$
$$0.001 \leq \frac{120}{180 n^4}$$
$$n^4 \leq \frac{120}{180 \cdot 0.001}$$
$$n \leq \sqrt[4]{\frac{120}{0.18}}$$
$$n \leq 5.08$$

Simpson's rule formula:
$\begin{aligned} S_n & =\frac{\Delta x}{3}\left(f\left(x_0\right)+4 f\left(x_1\right)+2 f\left(x_2\right)+4 f\left(x_3\right)+2 f\left(x_4\right)\right. \\ & \left.+\cdots+2 f\left(x_{n-2}\right)+4 f\left(x_{n-1}\right)+f\left(x_n\right)\right) .\end{aligned}$

Using 6 intervals

```{r}
f=function(x) {1/x^2}

# Define the limits of integration
a=1
b=2

# Number of intervals
n=6

simpsons_rule=function(f, a, b, n) {
  if (n %% 2 != 0) {
    stop("Number of subintervals must be even.")
  }
  
  h=(b - a) / n
  integral=f(a) + f(b)  # endpoints
  
  # Odd indexed points
  odd_sum=sum(sapply(seq(1, n, by = 2), function(i) f(a + i * h)))
  # Even indexed points
  even_sum=sum(sapply(seq(2, n-1, by = 2), function(i) f(a + i * h)))
  
  integral=integral + 4 * odd_sum + 2 * even_sum
  integral=integral * h / 3
  
  return(integral)
}

int=simpsons_rule(f, a, b, n)

actual=integrate(f, lower = 1, upper = 2)
abs(actual$value-int)
```

7. Use four iterations of Romberg integration to estimate $\pi=\int_0^1 \frac{4}{1+x^2} d x$. Comment on the accuracy of your result.


Recall the Trapezoidal rule:
$$
T=\frac{\Delta x}{2}\left(f\left(x_0\right)+2 f\left(x_1\right)+2 f\left(x_2\right)+\cdots+2 f\left(x_{n-1}\right)+f\left(x_n\right) .\right.
$$

Let $T(\Delta x)$ be the trapezoidal rule approximation, with step size $\Delta x$, to an integral $l$. The Romberg integration algorithm is
$$
\begin{gathered}
T_1(\Delta x)=\frac{4 T\left(\frac{\Delta x}{2}\right)-T(\Delta x)}{3} \\
T_2(\Delta x)=\frac{16 T_1\left(\frac{\Delta x}{2}\right)-T_1(\Delta x)}{3} \\
T_3(\Delta x)=\frac{64 T_2\left(\frac{\Delta x}{2}\right)-T_2(\Delta x)}{63} \\
\vdots \\
T_k(\Delta x)=\frac{2^{2 k} T_{k-1}\left(\frac{\Delta x}{2}\right)-T_{k-1}(\Delta x)}{2^{2 k}-1}
\end{gathered}
$$

```{r} 

# Define the function
f <- function(x) {
  4 / (1 + x^2)
}

# Romberg integration function
romberg_function <- function(f, a, b, n = 4) {
  deltax <- (b - a) / 2
  T <- (deltax / 2) * (f(a) + f(b))
  result <- matrix(NA, nrow = n, ncol = n)
  result[1, 1] <- T
  
  for (i in 2:n) {
    deltax <- deltax / 2
    sum <- 0
    for (k in 1:(2^(i - 1))) {
      sum <- sum + f(a + (2 * k - 1) * deltax)
    }
    T <- 0.5 * T + deltax * sum
    result[i, 1] <- T
    for (j in 2:i) {
      result[i, j] <- (4^(j-1) * result[i, j - 1] - result[i - 1, j - 1]) / (4^(j - 1) - 1)
    }
  }
  return(result)
}

# Call the romberg function 
result <- romberg_function(f, 0, 1)  
int = as.numeric(result[nrow(result), ncol(result)])

# Print the result
print(result)

#Check the pracma romberg function
romberg(f,0,1)

actual = integrate(f,0,1)

abs(actual$value-int)

```
The estimation of PI With 4 iterations of Romberg Integration yielded an absolute error of 0.1224692. 
